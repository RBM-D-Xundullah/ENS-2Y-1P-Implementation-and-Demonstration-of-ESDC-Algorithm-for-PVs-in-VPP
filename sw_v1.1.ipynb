{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<u>Initialize Cloud-AI Engine</u>__ \n",
    "> with a developed and distinct environment: __py39-VPP (Python 3.9.16)__\n",
    ">> cmd Run: __conda install -n (env) ipykernel --update-deps --force-reinstall__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Install/Verify Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (2.0.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sqlalchemy<2.0 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (1.4.48)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from sqlalchemy<2.0) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mariadb in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (1.1.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from mariadb) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (3.7.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rbm-workstation\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rbm-workstation\\anaconda3\\envs\\py39-vpp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user --upgrade pandas\n",
    "%pip install --user --upgrade \"sqlalchemy<2.0\"\n",
    "%pip install --user --upgrade mariadb\n",
    "%pip install --user --upgrade -U matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import mariadb\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<u>Configure Simulation Setup</u>__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Define output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory \"../Data/RawData/\" already exists.\n",
      "The directory \"../Data/ProcessedData/\" already exists.\n"
     ]
    }
   ],
   "source": [
    "savePath_1 = '../Data/RawData/'\n",
    "savePath_2 = '../Data/ProcessedData/'\n",
    "\n",
    "# create savePath_1 directory if it doesn't exist\n",
    "if not os.path.exists(savePath_1):\n",
    "    os.makedirs(savePath_1)\n",
    "    print(f\"System has created \\\"{savePath_1}\\\" directory.\")\n",
    "else:\n",
    "    print(f\"The directory \\\"{savePath_1}\\\" already exists.\")\n",
    "\n",
    "# create savePath_2 directory if it doesn't exist\n",
    "if not os.path.exists(savePath_2):\n",
    "    os.makedirs(savePath_2)\n",
    "    print(f\"System has created \\\"{savePath_2}\\\" directory.\")\n",
    "else:\n",
    "    print(f\"The directory \\\"{savePath_2}\\\" already exists.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define colunmns and rows of pandas output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 50)\n",
    "# pd.set_option('display.max_rows', 50000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<u>Configure Cloud Database Accessing System & Read Data</u>__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <u>Create __Cloud DB Access Engine__ with _SQLAlchemy_</u>\n",
    "> * I will use SQLAlchemy because it is recommended by Pandas DataFrame\n",
    "> * Link: https://pandas.pydata.org/docs/reference/api/pandas.read_sql_query.html\n",
    ">> * ENS is using __Maria DB__\n",
    ">> * Link: https://docs.sqlalchemy.org/en/14/dialects/mysql.html#module-sqlalchemy.dialects.mysql.mariadbconnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote Database Connected Successfully\n"
     ]
    }
   ],
   "source": [
    "# Format: mariadb+mariadbconnector://<user>:<password>@<host>[:<port>]/<dbname>\n",
    "try:\n",
    "    mariaDB_conn_engine = sqlalchemy.create_engine('mariadb+mariadbconnector://kmsg22:kmsg22@kmsg007.iptime.org:3306/kmsg_inverter')\n",
    "    print(\"Remote Database Connected Successfully\")\n",
    "except mariadb.Error as e:\n",
    "    print(f\"Error connecting to Remote Database Platform: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Find the List of Tables from the SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tbl_ppcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tbl_pvdat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tbl_pvdat_kaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tbl_pvdat_ks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       table_name\n",
       "0      tbl_ppcode\n",
       "1       tbl_pvdat\n",
       "2  tbl_pvdat_kaco\n",
       "3    tbl_pvdat_ks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl_list = pd.read_sql_query(\"SELECT table_name FROM information_schema.tables WHERE table_type='BASE TABLE';\", mariaDB_conn_engine)\n",
    "tbl_list "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Getting individual Table Data into distinct Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl_ppcode = pd.read_sql_query(\"SELECT * FROM kmsg_inverter.tbl_ppcode;\", mariaDB_conn_engine)\n",
    "# tbl_ppcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat = pd.read_sql_query(\"SELECT * FROM kmsg_inverter.tbl_pvdat\" , mariaDB_conn_engine)\n",
    "# tbl_pvdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl_pvdat_kaco = pd.read_sql_query(\"SELECT * FROM kmsg_inverter.tbl_pvdat_kaco\" , mariaDB_conn_engine)\n",
    "# tbl_pvdat_kaco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl_pvdat_ks = pd.read_sql_query(\"SELECT * FROM kmsg_inverter.tbl_pvdat_ks\" , mariaDB_conn_engine)\n",
    "# tbl_pvdat_ks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat.to_csv(f\"{savePath_1}tbl_pvdat.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<u>Data Preprocessing & Analysis</u>__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Working on __tbl_pvdat__</u>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check names of all columns as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tbl_pvdat.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> <div class=\"alert alert-block alert-info\"> <b>Note:</b> <i>DBeaver</i> is used to retrieve Comments. Column Description is <b>Translated</b>.</div>\n",
    "\n",
    "- `[✓] C_pcode =======> Power plant identification number`\n",
    "- <b>`[✓] D_date ========> storage time` </b>\n",
    "- `[✖] I_dev =========> device number`\n",
    "- `[✖] I_kind ========> 0KMSG, 1:Kstar, 2:Kaco`\n",
    "- `[✖] I_stat ========> 1STOP,2RUN,4ES,5WAIT`\n",
    "- `[✖] F_dcv =========> DC input voltage`\n",
    "- `[✖] F_dci =========> DC input current`\n",
    "- `[✖] F_dcp =========> DC input power`\n",
    "- `[✖] F_vr ==========> RS line voltage`\n",
    "- `[✖] F_vs ==========> ST line voltage`\n",
    "- `[✖] F_vt ==========> TR line voltage`\n",
    "- `[✖] F_ir ==========> R phase current`\n",
    "- `[✖] F_is ==========> S phase current`\n",
    "- `[✖] F_it ==========> T phase current`\n",
    "- <b>`[✓] F_rpower ======> instantaneous output power` </b>\n",
    "- `[✖] F_pf ==========> power factor`\n",
    "- `[✖] F_hz ==========> frequency`\n",
    "- `[✖] F_rpower_max ==> maximum instantaneous power generation`\n",
    "- `[✓] F_day_power ===> Accumulated power generation for the day`\n",
    "- `[✖] F_all_power ===> total cumulative power generation`\n",
    "- `[✓] I_day_powert ==> Power generation time of the day`\n",
    "- `[✓] I_all_powert ==> total cumulative power generation time`\n",
    "- `[✓] I_all_fant ====> fan operation time`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __<u> Analysis Power Plants </u>__\n",
    ">> Note from ENS: \n",
    ">>   * Power_Plant 2, C_pcode __41424011~41424012__ : Ansan-si, Gyeonggi-do\n",
    ">>   * Power_Plant 5, C_pcode __71780001~71780005__ : Seomyeon, Gyeongju-si, Gyeongsangbuk-do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Check variations of __C_pcode__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat['C_pcode'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Working with __PV_Source : 41424011~2__</u>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate Power Plant by utilizing __C_pcode__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat_41424011 = tbl_pvdat[tbl_pvdat['C_pcode']=='41424011']\n",
    "tbl_pvdat_41424012 = tbl_pvdat[tbl_pvdat['C_pcode']=='41424012']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop down C_pcode column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl_pvdat_41424011 = tbl_pvdat_41424011.drop(['C_pcode'], axis=1)\n",
    "# tbl_pvdat_41424012 = tbl_pvdat_41424012.drop(['C_pcode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat_41424011 = pd.concat([tbl_pvdat_41424011], ignore_index=True, sort=False)\n",
    "tbl_pvdat_41424012 = pd.concat([tbl_pvdat_41424012], ignore_index=True, sort=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Convert Date-Time into Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'D_date' column to a pandas datetime object\n",
    "tbl_pvdat_41424011['D_date'] = pd.to_datetime(tbl_pvdat_41424011['D_date'])\n",
    "tbl_pvdat_41424012['D_date'] = pd.to_datetime(tbl_pvdat_41424012['D_date'])\n",
    "# Convert the 'D_date' column to a formatted string\n",
    "tbl_pvdat_41424011['D_date_formatted'] = tbl_pvdat_41424011['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "tbl_pvdat_41424012['D_date_formatted'] = tbl_pvdat_41424012['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "# Convert the 'D_date_formatted' column to a pandas datetime object\n",
    "tbl_pvdat_41424011['D_date_formatted'] = pd.to_datetime(tbl_pvdat_41424011['D_date_formatted'])\n",
    "tbl_pvdat_41424012['D_date_formatted'] = pd.to_datetime(tbl_pvdat_41424012['D_date_formatted'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_41424011 = tbl_pvdat_41424011[2000:][['D_date_formatted', 'F_rpower', 'F_day_power']]\n",
    "PV_41424012 = tbl_pvdat_41424012[2000:][['D_date_formatted', 'F_rpower', 'F_day_power']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_41424011 = pd.concat([PV_41424011], ignore_index=True, sort=False)\n",
    "PV_41424012 = pd.concat([PV_41424012], ignore_index=True, sort=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_41424011 = PV_41424011.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})\n",
    "PV_41424012 = PV_41424012.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_41424011['timestamp'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PV_41424012[:]\n",
    "i    = 1\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams['font.size'] = '9'\n",
    "for counter in range(1,len(data.columns)):\n",
    "    plt.subplot(len(data.columns), 1, i)\n",
    "    plt.plot(data.values[:, 0], data.values[:, counter], color = 'gray')\n",
    "    # plt.plot(data.values[:, counter], color = 'gray')\n",
    "    plt.title(data.columns[counter], y=0.8, loc='right')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('')\n",
    "    plt.grid(True)\n",
    "    i = i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save as gzip file in a local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_41424011.to_csv(f\"{savePath_2}PV_41424011.gzip\", index=False, compression=\"gzip\")\n",
    "PV_41424012.to_csv(f\"{savePath_2}PV_41424012.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Working with __PV_Source : 71780001~5__</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate Power Plant by utilizing __C_pcode__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat_71780001 = tbl_pvdat[tbl_pvdat['C_pcode']=='71780001']\n",
    "tbl_pvdat_71780002 = tbl_pvdat[tbl_pvdat['C_pcode']=='71780002']\n",
    "tbl_pvdat_71780003 = tbl_pvdat[tbl_pvdat['C_pcode']=='71780003']\n",
    "tbl_pvdat_71780004 = tbl_pvdat[tbl_pvdat['C_pcode']=='71780004']\n",
    "tbl_pvdat_71780005 = tbl_pvdat[tbl_pvdat['C_pcode']=='71780005']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat_71780001.to_csv(f\"{savePath}tbl_pvdat_71780001.gzip\", index=False, compression=\"gzip\")\n",
    "tbl_pvdat_71780002.to_csv(f\"{savePath}tbl_pvdat_71780002.gzip\", index=False, compression=\"gzip\")\n",
    "tbl_pvdat_71780003.to_csv(f\"{savePath}tbl_pvdat_71780003.gzip\", index=False, compression=\"gzip\")\n",
    "tbl_pvdat_71780004.to_csv(f\"{savePath}tbl_pvdat_71780004.gzip\", index=False, compression=\"gzip\")\n",
    "tbl_pvdat_71780005.to_csv(f\"{savePath}tbl_pvdat_71780005.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop down C_pcode column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl_pvdat_71780001 = tbl_pvdat_71780001.drop(['C_pcode'], axis=1)\n",
    "# tbl_pvdat_71780002 = tbl_pvdat_71780002.drop(['C_pcode'], axis=1)\n",
    "# tbl_pvdat_71780003 = tbl_pvdat_71780003.drop(['C_pcode'], axis=1)\n",
    "# tbl_pvdat_71780004 = tbl_pvdat_71780004.drop(['C_pcode'], axis=1)\n",
    "# tbl_pvdat_71780005 = tbl_pvdat_71780005.drop(['C_pcode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_pvdat_71780001 = pd.concat([tbl_pvdat_71780001], ignore_index=True, sort=False)\n",
    "tbl_pvdat_71780002 = pd.concat([tbl_pvdat_71780002], ignore_index=True, sort=False)\n",
    "tbl_pvdat_71780003 = pd.concat([tbl_pvdat_71780003], ignore_index=True, sort=False)\n",
    "tbl_pvdat_71780004 = pd.concat([tbl_pvdat_71780004], ignore_index=True, sort=False)\n",
    "tbl_pvdat_71780005 = pd.concat([tbl_pvdat_71780005], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Convert Date-Time into Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'D_date' column to a pandas datetime object\n",
    "tbl_pvdat_71780001['D_date'] = pd.to_datetime(tbl_pvdat_71780001['D_date'])\n",
    "tbl_pvdat_71780002=tbl_pvdat_71780002[1:]\n",
    "tbl_pvdat_71780002['D_date'] = pd.to_datetime(tbl_pvdat_71780002['D_date'])\n",
    "tbl_pvdat_71780003['D_date'] = pd.to_datetime(tbl_pvdat_71780003['D_date'])\n",
    "tbl_pvdat_71780004['D_date'] = pd.to_datetime(tbl_pvdat_71780004['D_date'])\n",
    "tbl_pvdat_71780005['D_date'] = pd.to_datetime(tbl_pvdat_71780005['D_date'])\n",
    "# Convert the 'D_date' column to a formatted string\n",
    "tbl_pvdat_71780001['D_date_formatted'] = tbl_pvdat_71780001['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "tbl_pvdat_71780002['D_date_formatted'] = tbl_pvdat_71780002['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "tbl_pvdat_71780003['D_date_formatted'] = tbl_pvdat_71780003['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "tbl_pvdat_71780004['D_date_formatted'] = tbl_pvdat_71780004['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "tbl_pvdat_71780005['D_date_formatted'] = tbl_pvdat_71780005['D_date'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "# Convert the 'D_date_formatted' column to a pandas datetime object\n",
    "tbl_pvdat_71780001['D_date_formatted'] = pd.to_datetime(tbl_pvdat_71780001['D_date_formatted'])\n",
    "tbl_pvdat_71780002['D_date_formatted'] = pd.to_datetime(tbl_pvdat_71780002['D_date_formatted'])\n",
    "tbl_pvdat_71780003['D_date_formatted'] = pd.to_datetime(tbl_pvdat_71780003['D_date_formatted'])\n",
    "tbl_pvdat_71780004['D_date_formatted'] = pd.to_datetime(tbl_pvdat_71780004['D_date_formatted'])\n",
    "tbl_pvdat_71780005['D_date_formatted'] = pd.to_datetime(tbl_pvdat_71780005['D_date_formatted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_71780001 = tbl_pvdat_71780001[70000:][['D_date_formatted', 'F_rpower', 'F_day_power']]\n",
    "PV_71780002 = tbl_pvdat_71780002[70000:][['D_date_formatted', 'F_rpower', 'F_day_power']]\n",
    "PV_71780003 = tbl_pvdat_71780003[70000:][['D_date_formatted', 'F_rpower', 'F_day_power']]\n",
    "PV_71780004 = tbl_pvdat_71780004[70000:][['D_date_formatted', 'F_rpower', 'F_day_power']]\n",
    "PV_71780005 = tbl_pvdat_71780005[70000:][['D_date_formatted', 'F_rpower', 'F_day_power']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_71780001 = pd.concat([PV_71780001], ignore_index=True, sort=False)\n",
    "PV_71780002 = pd.concat([PV_71780002], ignore_index=True, sort=False)\n",
    "PV_71780003 = pd.concat([PV_71780003], ignore_index=True, sort=False)\n",
    "PV_71780004 = pd.concat([PV_71780004], ignore_index=True, sort=False)\n",
    "PV_71780005 = pd.concat([PV_71780005], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_71780001 = PV_71780001.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})\n",
    "PV_71780002 = PV_71780002.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})\n",
    "PV_71780003 = PV_71780003.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})\n",
    "PV_71780004 = PV_71780004.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})\n",
    "PV_71780005 = PV_71780005.rename(columns={'D_date_formatted': 'timestamp', 'F_rpower': 'inst_power', 'F_day_power': 'day_power'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_71780001['timestamp'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PV_71780001[:]\n",
    "i    = 1\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams['font.size'] = '9'\n",
    "for counter in range(1,len(data.columns)):\n",
    "    plt.subplot(len(data.columns), 1, i)\n",
    "    plt.plot(data.values[:, 0], data.values[:, counter], color = 'gray')\n",
    "    # plt.plot(data.values[:, counter], color = 'gray')\n",
    "    plt.title(data.columns[counter], y=0.8, loc='right')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('')\n",
    "    plt.grid(True)\n",
    "    i = i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save as gzip file in a local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_71780001.to_csv(f\"{savePath_2}PV_71780001.gzip\", index=False, compression=\"gzip\")\n",
    "PV_71780002.to_csv(f\"{savePath_2}PV_71780002.gzip\", index=False, compression=\"gzip\")\n",
    "PV_71780003.to_csv(f\"{savePath_2}PV_71780003.gzip\", index=False, compression=\"gzip\")\n",
    "PV_71780004.to_csv(f\"{savePath_2}PV_71780004.gzip\", index=False, compression=\"gzip\")\n",
    "PV_71780005.to_csv(f\"{savePath_2}PV_71780005.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ens1==py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6dc7d7445c97e157d0435c8b952256aac918af18d11ae3628ca45838ce0a8be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
